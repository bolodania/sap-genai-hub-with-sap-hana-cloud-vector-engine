{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this use case, we will embark on a journey to explore the capabilities of **SAP HANA Cloud vector engine**, **SAP Generative AI Hub** and the **Langchain** Framework. The goal is to equip you with the knowledge and skills to handle unstructured and semi-structured data and build efficient applications.\n",
    "\n",
    "Embed structured and semi-structured data using **Large Language Models** (LLMs) from **SAP Generative AI Hub**. Once the data is embedded, it will be stored in **SAP HANA Cloud** helping to store and query vector embeddings seamlessly. \n",
    "\n",
    "\n",
    "## About the data set\n",
    "\n",
    "The data set is a product catalog of IT accessory products. Here are the main attributes and their descriptions based on the sample data:\n",
    "\n",
    "|Field          |Description            |\n",
    "----------------|-----------------------\n",
    "|**PRODUCT_ID**| A unique identifier for each product.|\n",
    "|**PRODUCT_NAME**| The name of the product, which typically includes the brand and the model.|\n",
    "|**CATEGORY**| The general category of the product, which is \"IT Accessories\" for all entries sampled.|\n",
    "|**DESCRIPTION**| A detailed description of the product, highlighting key features and specifications.|\n",
    "|**UNIT_PRICE**| The price of the product in Euros.|\n",
    "|**UNIT_MEASURE**| The unit of measure for the product, typically \"Each\" indicating pricing per item.|\n",
    "|**SUPPLIER_ID**| A unique identifier for the supplier of the product.|\n",
    "|**SUPPLIER_NAME**| The name of the supplier.|\n",
    "|**LEAD_TIME_DAYS**| The number of days it takes from order to delivery.|\n",
    "|**MIN_ORDER**| The minimum order quantity required.|\n",
    "|**CURRENCY**| The currency of the transaction, which is \"EURO\" for all entries.|\n",
    "|**SUPPLIER_COUNTRY**| The country where the supplier is located, which is \"Germany\" for all sampled entries.|\n",
    "|**SUPPLIER_ADDRESS**| The physical address of the supplier.|\n",
    "|**AVAILABILITY_DAYS**| The number of days the product is available for delivery.|\n",
    "|**SUPPLIER_CITY**| The city where the supplier is located.|\n",
    "|**STOCK_QUANTITY**| The quantity of the product currently in stock.|\n",
    "|**MANUFACTURER**| The company that manufactured the product.|\n",
    "|**CITY_LAT**| Geographical coordinates of the city (latitude)|\n",
    "|**CITY_LONG**| Geographical coordinates of the city (longitude).|\n",
    "|**RATING:**| A rating for the product, which are on a scale from 1 to 5.|\n",
    "\n",
    "</br>\n",
    "\n",
    "> This dataset is structured to support various business operations such as inventory management, order processing, and logistics planning, providing a comprehensive view of product offerings, supplier details, and stock levels. Each entry is highly detailed, suggesting the dataset could be used for analytical purposes, such as optimizing supply chain operations or analyzing sales and marketing strategies.\n",
    "\n",
    "</br>\n",
    "\n",
    "## Retrieval Augmented Generation in generative AI Hub using SAP HANA vector search\n",
    "\n",
    "### Hands-on Retrieval Augmented Generation (RAG) workflow \n",
    "\n",
    "The Retrieval Augmented Generation use case process consists of steps to be completed as seen in the graphic below. \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "> ![title](./images/rag_full.png)\n",
    "\n",
    "<br> \n",
    "\n",
    "\n",
    "#### Indexing Process\n",
    "1. Business documents that should be used for answering user questions are fed into the model. The contents of the files are split into smaller chunks.\n",
    "    >\"Chunking\" (and sometimes called \"llm chunking\") refers to dividing a large text corpus into smaller, manageable pieces or segments. Each recursive chunking part acts as a standalone unit of information that can be individually indexed and retrieved. \n",
    "2. Embedding functions are used to create embeddings from the file/document chunks.\n",
    "    >Embeddings refer to dense, continuous vectors representing text in a high-dimensional space. These vectors serve as coordinates in a semantic space, capturing the relationships and meanings between words.\n",
    "3. The embeddings are then stored as vectors in the SAP HANA Cloud Database.\n",
    "#### Retrieval Process\n",
    "1. A query or prompt is submitted.\n",
    "2. The query embedded into a vector form.\n",
    "3. The query vector is compared to the values stored as vectors in SAP HANA Cloud via a similarity/semantic search.\n",
    "4. The most appropriate and relevant results are identified.\n",
    "5. And forwarded, along with the original query, to a large language model such as GPT-4o.\n",
    "6. The LLM uses the results of the HANA vector search to augment its own searching capabilities, and the final answer is returned to the user.\n",
    "\n",
    "\n",
    "<!-- - Uses Python code to generate responses for queries using the SDK.\n",
    "\n",
    "- Formats the query and invokes the Generative AI Hub SDK to fetch responses. -->\n",
    "\n",
    "### Implementing RAG Embeddings\n",
    "\n",
    "- Prepare the documentation for the product catalog in CSV format with each row representing a product.\n",
    "\n",
    "- Connect to the HANA vector storage instance and create a table to store the documentation data.\n",
    "\n",
    "- Populate the table with data and create a REAL_VECTOR column to store embeddings.\n",
    "\n",
    "- Use the Generative AI Hub SDK to define a function to generate embeddings for prompts and perform similarity search using the embeddings.\n",
    "\n",
    "### Enhancing Query Responses\n",
    "\n",
    "- Define a prompt template to provide context to queries.\n",
    "\n",
    "- Modify the function to query the LLM (Large Language Model) based on the prompt template.\n",
    "\n",
    "- Test the model's response using specific queries related to the node library, ensuring it provides contextually relevant responses based on embeddings.\n",
    "\n",
    "> Retrieval augmented generation optimizes the output of large language models by applying more context to prompts.\n",
    "\n",
    "</br>\n",
    "\n",
    "<!-- ### SAP HANA Cloud vector engine\n",
    "\n",
    "Storing vector embeddings within the same database is a strategic move that aligns seamlessly with SAP's commitment to providing a unified platform. This integration eliminates the hurdles posed by data silos, offering a holistic approach to data management. In SAP HANA Cloud, the storage of vector embeddings is seamlessly integrated into the platform's existing structure, allowing users to store them in a designated table. Developers can perform SQL-like queries effortlessly. \n",
    "\n",
    "This means you can execute joins, apply filters, and perform selects by combining vector embeddings with various data types, including transactional, spatial, graph, and JSON data, all within the same SQL environment. The Vector Engine ensures a user-friendly experience, eliminating the need for extensive learning or the adoption of new querying methodologies. Essentially, working with vector embeddings in SAP HANA Cloud is as straightforward as crafting queries in a standard SQL database, offering familiarity and ease of use for developers. -->\n",
    "\n",
    "<!-- ### Hands-on Retrieval Augmented Generation (RAG) workflow  -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- 1. Documents to be included in vector analysis are fed into the model.\n",
    "\n",
    "2. The contents of the files are split into smaller chunks.\n",
    "\n",
    "3. Embedding functions are used to create embeddings from the file/document chunks.\n",
    "\n",
    "4. The embeddings are then stored as vectors in the SAP HANA Cloud Database.\n",
    "\n",
    "5. When a query or prompt is submitted, the query itself is then embedded into vector form.\n",
    "\n",
    "6. The query vector is compared to the values stored as vectors in SAP HANA Cloud via a similarity/semantic search.\n",
    "\n",
    "7. The most appropriate results are forwarded, along with the original query, to a large language model such as Chat GPT.\n",
    "\n",
    "8. The LLM uses the results of the HANA vector search to augment its own searching capabilities, and the final answer is returned to the user. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and configuration\n",
    "\n",
    "The following Python modules are to be installed during this hands-on introduction. \n",
    "\n",
    "#### **hdbcli**\n",
    "\n",
    "The Python Database API Specification v2.0 (PEP 249) defines a set of methods that provides a consistent database interface independent of the actual database being used. The Python extension module for SAP HANA implements PEP 249. Once you install the module, you can access and change the information in SAP HANA databases from Python.\n",
    "\n",
    "For more information, please see https://pypi.org/project/hdbcli/\n",
    "\n",
    "#### **generative-ai-hub-sdk**\n",
    "\n",
    "With this SAP python SDK you can leverage the power of generative Models like chatGPT available in SAP's generative AI Hub.\n",
    "\n",
    "For more information, please see https://pypi.org/project/generative-ai-hub-sdk/\n",
    "\n",
    "<!-- #### **Folium**\n",
    "\n",
    "Folium builds on the data wrangling strengths of the Python ecosystem and the mapping strengths of the Leaflet.js library. Manipulate your data in Python, then visualize it in a Leaflet map via folium.\n",
    "\n",
    "For more information, please see https://pypi.org/project/folium/ -->\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Note:** Jupyter Notebook kernel restart required after package installation.\n",
    "\n",
    "\n",
    "</br>\n",
    "\n",
    "#### Install Python packages\n",
    "\n",
    "Run the following package installations. **pip** is the package installer for Python. You can use pip to install packages from the Python Package Index and other indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install hdbcli --break-system-packages\n",
    "%pip install generative-ai-hub-sdk[all] --break-system-packages\n",
    "%pip install python-dotenv --break-system-packages\n",
    "\n",
    "# kernel restart required!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restart Python kernel\n",
    "\n",
    "The Python kernel needs to be restarted before continuing. \n",
    "\n",
    "> ![title](./images/config_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure SAP Generative AI Hub credentials\n",
    "\n",
    "Execute the configuration module below to enable access to SAP Generative AI foundation models. This configuration is automatically done by running configuration module in the code block.\n",
    "\n",
    "You could also set up the same by running a terminal command: **aicore configure**\n",
    "\n",
    "\n",
    "</br>\n",
    "\n",
    "> Please ensure that the Python kernel was restarted!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative AI Config\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "# Get the AI Core URL from environment variables\n",
    "URL = os.getenv('AICORE_AUTH_URL')\n",
    "# Get the AI Core client ID from environment variables\n",
    "CLIENT_ID = os.getenv('AICORE_CLIENT_ID')\n",
    "# Get the AI Core client secret from environment variables\n",
    "CLIENT_SECRET = os.getenv('AICORE_CLIENT_SECRET')\n",
    "# Get the AI Core client ID from environment variables\n",
    "RESOURCE_GROUP = os.getenv('AICORE_RESOURCE_GROUP')\n",
    "# Get the AI Core client secret from environment variables\n",
    "API_URL = os.getenv('AICORE_BASE_URL')\n",
    "\n",
    "# Determine the user's home directory\n",
    "home_dir = os.path.expanduser('~')\n",
    "aicore_dir = os.path.join(home_dir, '.aicore')\n",
    "\n",
    "# Create the .aicore directory if it doesn't exist\n",
    "os.makedirs(aicore_dir, exist_ok=True)\n",
    "\n",
    "# Define the configuration data\n",
    "config_data = {\n",
    "    \"AICORE_AUTH_URL\": URL,\n",
    "    \"AICORE_CLIENT_ID\": CLIENT_ID,\n",
    "    \"AICORE_CLIENT_SECRET\": CLIENT_SECRET,\n",
    "    \"AICORE_RESOURCE_GROUP\": RESOURCE_GROUP,\n",
    "    \"AICORE_BASE_URL\": API_URL\n",
    "}\n",
    "\n",
    "# Path to the config.json file\n",
    "config_path = os.path.join(aicore_dir, 'config.json')\n",
    "\n",
    "# Write the config data to config.json\n",
    "with open(config_path, 'w') as config_file:\n",
    "    json.dump(config_data, config_file, indent=4)\n",
    "\n",
    "# print(f\"Your resource group is {RESOURCE_GROUP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the LLM model\n",
    "LLM is initialized as an instance of ChatOpenAI with a model **gpt-4o**. This is used for generating responses or interacting in a chat-like environment.\n",
    "\n",
    "> **IMPORTANT!** here you are connecting to the **gpt-4o** model you've deployed as part of the first exercise.\n",
    "<!-- We can compare how the output produced by RAG is different from the output when we directly pass the prompt to the model. If we directly pass the prompt to the model without RAG, this will be the output. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set llm\n",
    "\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "\n",
    "proxy_client = get_proxy_client('gen-ai-hub')\n",
    "llm = ChatOpenAI(proxy_model_name='gpt-4o', proxy_client=proxy_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask LLM without context\n",
    "\n",
    "After completing the configuration we are ready to ask the first question directly to LLM (gpt-4o) without any business product context to find us products with a rating of 4 and more. The response is arbitrary and does not relate to our product data. \n",
    "\n",
    "</br>\n",
    "\n",
    "> **Note** We can solve this problem by following the next steps in implementing RAG Embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "question = \"Find 5 products with a rating of 4 and more.\"\n",
    "llm.temperature=0.7\n",
    "response = llm.invoke(question)\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Retrieval Augmented Generation (RAG)\n",
    "\n",
    "### Prepare the documentation for the product catalog in CSV format with each row representing a product\n",
    "\n",
    "This code snippet demonstrates how to load and process text data from a CSV file using the `CSVLoader` from the `langchain.document_loaders.csv_loader` module.\n",
    "\n",
    "This process is useful for handling large text data, making it more manageable or suitable for further processing, analysis, or input into machine learning models, especially when dealing with limitations on input size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# Process CSV data file\n",
    "loader = CSVLoader(\n",
    "    file_path=\"data/product_catalog.csv\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \";\",\n",
    "        \"quotechar\": '\"'\n",
    "        \n",
    "    },\n",
    ")\n",
    "\n",
    "# Process data\n",
    "text_documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "text_chunks = text_splitter.split_documents(text_documents)\n",
    "\n",
    "print(f\"Number of document chunks: {len(text_chunks)}\")\n",
    "\n",
    "for chunks in text_chunks:\n",
    "    print(chunks.metadata)\n",
    "    print(chunks.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At this point we have implemented the first RAG step - generated text chunks from source data\n",
    "> \n",
    "> ![rag_indexing_1](./images/rag_indexing_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAP HANA Cloud vector engine\n",
    "\n",
    "Storing vector embeddings within the same database is a strategic move that aligns seamlessly with SAP's commitment to providing a unified platform. This integration eliminates the hurdles posed by data silos, offering a holistic approach to data management. In SAP HANA Cloud, the storage of vector embeddings is seamlessly integrated into the platform's existing structure, allowing users to store them in a designated table. Developers can perform SQL-like queries effortlessly. \n",
    "\n",
    "This means you can execute joins, apply filters, and perform selects by combining vector embeddings with various data types, including transactional, spatial, graph, and JSON data, all within the same SQL environment. The Vector Engine ensures a user-friendly experience, eliminating the need for extensive learning or the adoption of new querying methodologies. Essentially, working with vector embeddings in SAP HANA Cloud is as straightforward as crafting queries in a standard SQL database, offering familiarity and ease of use for developers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to the HANA vector storage instance\n",
    "\n",
    "The provided Python script imports database connection modules and initiates a connection to a SAP HANA Cloud instance using the `dbapi` module. The user is prompted to enter their username and password, which are then used to establish a secure connection to the SAP HANA Cloud database. \n",
    "\n",
    "The `langchain_community.vectorstores.hanavector` library, specifically the `HanaDB` class, from the LangChain community, is designed to interact with vector data stored in SAP HANA Cloud database, and enables developers to utilize SAP HANA Cloud's advanced capabilities for managing and querying vector data, in the context of AI and machine learning applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HC Vector Engine\n",
    "import os\n",
    "from hdbcli import dbapi\n",
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "\n",
    "# Get the HANA Cloud username from environment variables\n",
    "HANA_USER = os.getenv('HANA_VECTOR_USER')\n",
    "# Get the HANA Cloud password from environment variables\n",
    "HANA_PASS = os.getenv('HANA_VECTOR_PASS')\n",
    "# Get the HANA Cloud host from environment variables\n",
    "HANA_HOST = os.getenv('HANA_VECTOR_HOST')\n",
    "\n",
    "# Establish a connection to the HANA Cloud database using HANA_ML package\n",
    "connection = dbapi.connect(\n",
    "    address=HANA_HOST,\n",
    "    port=443,\n",
    "    user=HANA_USER,\n",
    "    password=HANA_PASS,\n",
    "    autocommit=True,\n",
    "    sslValidateCertificate=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and store embeddings in SAP HANA Cloud\n",
    "\n",
    "We will be using two types of Embedding Models to generate the embeddings: **text-embedding-ada-002** from OpenAI and **SAP_NEB.20240715** from SAP.\n",
    "\n",
    "#### Generate and store embeddings in SAP HANA Cloud with the help of Generative AI Hub and text-embedding-ada-002 model\n",
    "\n",
    "Run the test below using functionality provided by the generative-ai-hub-sdk by making a call to the **text-embedding-ada-002** model via SAP Generative AI foundation-models as initial test.  \n",
    "\n",
    "> **IMPORTANT!** here you are connecting to the embedding model **text-embedding-ada-002** you've deployed as part of the first exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test embeddings\n",
    "\n",
    "from gen_ai_hub.proxy.native.openai import embeddings\n",
    "\n",
    "response = embeddings.create(\n",
    "    input=\"SAP Generative AI Hub is awesome!\",\n",
    "    model_name=\"text-embedding-ada-002\"\n",
    "    \n",
    ")\n",
    "print(response.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the embedding model\n",
    "Embeddings are vector representations of text data that incorporate the semantic meaning of the text. Define the embeddings object that generates embeddings from text data using the **text-embedding-ada-002** model. This function will be used to generate embeddings from the user's prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings\n",
    "\n",
    "from gen_ai_hub.proxy.langchain import OpenAIEmbeddings\n",
    "open_ai_embedding_model = OpenAIEmbeddings(proxy_model_name='text-embedding-ada-002', chunk_size=100, max_retries=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the table with data and creates a REAL_VECTOR column to store embeddings\n",
    "\n",
    "Create a LangChain VectorStore interface for the HANA database and specify the table (collection) to use for accessing the vector embeddings. Embeddings are vector representations of text data that incorporate the semantic meaning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "#Create a LangChain VectorStore interface for the HANA database and specify the table (collection) to use for accessing the vector embeddings\n",
    "db_ada_table = HanaDB(\n",
    "    embedding=open_ai_embedding_model, \n",
    "    connection=connection, \n",
    "    table_name=\"PRODUCTS_IT_ACCESSORY_ADA_\"+ HANA_USER,\n",
    "    content_column=\"VEC_TEXT\", # the original text description of the product details\n",
    "    metadata_column=\"VEC_META\", # metadata associated with the product details\n",
    "    vector_column=\"VEC_VECTOR\" # the vector representation of each product \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete already existing documents from the table\n",
    "db_ada_table.delete(filter={})\n",
    "\n",
    "# add the loaded document chunks\n",
    "db_ada_table.add_documents(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify product embeddings in SAP HANA Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the table to verify embeddings\n",
    "cursor = connection.cursor()\n",
    "sql = f'SELECT VEC_TEXT, TO_NVARCHAR(VEC_VECTOR) FROM \"{db_ada_table.table_name}\"'\n",
    "\n",
    "cursor.execute(sql)\n",
    "vectors = cursor.fetchall()\n",
    "\n",
    "for vector in vectors:\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At this point we have implemented the Indexing Process part of RAG\n",
    "> \n",
    "> ![rag_indexing_2](./images/rag_indexing_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing a Vector Search to Find Relevant Products  \n",
    "\n",
    "## Vector Search Using OpenAI's Embedding Model (*text-embedding-ada-002*)\n",
    "\n",
    "In this step, we use the **text-embedding-ada-002** model to convert a natural language query into a vector representation and retrieve the most relevant records from a database using **vector similarity search**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Query \n",
    "question = \"Suggest a keyboard with a rating 4 or more.\"\n",
    "# Using an embedding model (text-embedding-ada-002), we transform the text query into a numerical vector:\n",
    "query_vector = open_ai_embedding_model.embed_query(question)\n",
    "\n",
    "# We construct an SQL query that retrieves the top 10 most relevant records based on cosine similarity:\n",
    "#       COSINE_SIMILARITY: Measures how similar two vectors are. A higher value means a better match.\n",
    "#       TO_REAL_VECTOR('{qv}'): Converts the query vector into the correct SQL-compatible format.\n",
    "#       ORDER BY COSINE_SIMILARITY DESC: Ensures that the best matches appear at the top.\n",
    "sql_vector_search_ada = '''SELECT TOP {k}  VEC_TEXT, \"{metric}\"(\"VEC_VECTOR\", TO_REAL_VECTOR('{qv}')) as SCORING\n",
    "        FROM {table}\n",
    "        ORDER BY \"{metric}\"(\"VEC_VECTOR\", TO_REAL_VECTOR('{qv}')) {sort}'''.format(k=10, metric=\"COSINE_SIMILARITY\", qv=query_vector, table=db_ada_table.table_name, sort=\"DESC\")\n",
    "\n",
    "# We execute the SQL statement using the database cursor. This fetches the top 10 relevant results based on vector similarity.\n",
    "cursor.execute(sql_vector_search_ada)\n",
    "vectors = cursor.fetchall()\n",
    "\n",
    "#  we iterate over the retrieved results and print them:\n",
    "for vector in vectors:\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search Using SAP's Embedding Model (*SAP_NEB.20240715*)\n",
    "\n",
    "You will:\n",
    "\n",
    "1. **Create a table** in SAP HANA to store text data and generate vector embeddings using **SAP_NEB.20240715**.  \n",
    "2. **Insert product descriptions** into the table, allowing automatic embedding generation.  \n",
    "3. **Perform a vector search** to retrieve the most relevant products based on semantic similarity.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a table with automatic vector embeddings \n",
    "\n",
    "* `VEC_TEXT`: Stores the original text (e.g., product descriptions).\n",
    "* `VEC_META`: Stores metadata about the product (e.g., supplier, price, etc.).\n",
    "* `VEC_VECTOR`: Stores vector embeddings automatically generated from VEC_TEXT using SAP_NEB.20240715.\n",
    "* `VECTOR_EMBEDDING(\"VEC_TEXT\", 'DOCUMENT', 'SAP_NEB.20240715')`: Generates vector embeddings from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name_sap = \"PRODUCTS_IT_ACCESSORY_SAP_\"+ HANA_USER\n",
    "model_name_sap = \"SAP_NEB.20240715\"\n",
    "\n",
    "# Try dropping the table (SAP HANA will handle it if it doesn’t exist)\n",
    "drop_table_sql = f\"DROP TABLE {table_name_sap}\"\n",
    "try:\n",
    "    cursor.execute(drop_table_sql)\n",
    "    print(f\"Table {table_name_sap} dropped successfully.\")\n",
    "except:\n",
    "    print(f\"Table {table_name_sap} did not exist or could not be dropped.\")\n",
    "\n",
    "# Now create the table\n",
    "sql_vector_sap_table = '''CREATE COLUMN TABLE {table}(\n",
    "    \"VEC_TEXT\" NVARCHAR(5000),\n",
    "    \"VEC_META\" NVARCHAR(5000),\n",
    "    \"VEC_VECTOR\" REAL_VECTOR GENERATED ALWAYS AS VECTOR_EMBEDDING(\"VEC_TEXT\", 'DOCUMENT', '{model}')\n",
    ")'''.format(table=table_name_sap, model=model_name_sap)\n",
    "\n",
    "cursor.execute(sql_vector_sap_table)\n",
    "print(f\"Table {table_name_sap} created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting data in SAP HANA Cloud\n",
    "\n",
    "* We loop through `text_documents`, which contains product descriptions and metadata.\n",
    "* Convert metadata into **JSON format** for easier storage.\n",
    "* Use `INSERT INTO` to add text and metadata to the SAP HANA table.\n",
    "* **Embeddings are automatically generated** when the text is inserted into the `VEC_TEXT` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name_sap=\"PRODUCTS_IT_ACCESSORY_SAP_\"+ HANA_USER\n",
    "\n",
    "for doc in text_documents:\n",
    "    metadata_json = json.dumps(doc.metadata, ensure_ascii=False)  # Convert metadata to JSON string\n",
    "    sql = f\"INSERT INTO {table_name_sap} (VEC_TEXT, VEC_META) VALUES (?, ?)\"\n",
    "    cursor.execute(sql, [doc.page_content, metadata_json])\n",
    "\n",
    "print(\"Data successfully inserted into SAP HANA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the table to verify stored embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve stored embeddings from the table to verify the data.\n",
    "sql = f\"SELECT VEC_TEXT, TO_NVARCHAR(VEC_VECTOR) FROM {table_name_sap}\"\n",
    "cursor.execute(sql)\n",
    "output_select_embed_sap_model = cursor.fetchall()\n",
    "\n",
    "# Convert to a readable JSON format.\n",
    "output_select_embed_sap_model_json = json.dumps([\n",
    "            {\"text\":item[0], \"embedding\":item[1]}\n",
    "            for item in output_select_embed_sap_model\n",
    "        ], indent=4)\n",
    "\n",
    "print(output_select_embed_sap_model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a vector search using SAP's embedding model\n",
    "\n",
    "We convert a natural language query into a vector and find the most relevant results using cosine similarity.\n",
    "\n",
    "* `VECTOR_EMBEDDING('{question}', 'QUERY', 'SAP_NEB.20240715')` converts the search query into a vector.\n",
    "* `COSINE_SIMILARITY(..., VEC_VECTOR)` computes similarity scores between the query and stored embeddings.\n",
    "* `ORDER BY DESC` ensures the most relevant results appear at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Suggest a keyboard with a rating 4 or more.\"\n",
    "vector_function_sql = f\"COSINE_SIMILARITY(VECTOR_EMBEDDING('{question}', 'QUERY', 'SAP_NEB.20240715'), VEC_VECTOR)\"\n",
    "sql_vector_search_sap = '''SELECT TOP {k} VEC_TEXT, {metric} as SCORING\n",
    "        FROM {table}\n",
    "        ORDER BY {metric} {sort}'''.format(k=10, metric=vector_function_sql, table=table_name_sap, sort=\"DESC\")\n",
    "\n",
    "cursor.execute(sql_vector_search_sap)\n",
    "output_suggestion_sap_model = cursor.fetchall()\n",
    "\n",
    "# Convert to a readable JSON format.\n",
    "output_suggestion_sap_model_json = json.dumps([\n",
    "            {\"text\":item[0], \"score\":item[1]}\n",
    "            for item in output_suggestion_sap_model\n",
    "        ], indent=4)\n",
    "\n",
    "print(output_suggestion_sap_model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At this point we have successfully implemented the first step of Retrieval Process and enabled semantic vector similarity search to **retrieve relevant results from SAP HANA Cloud** based on user question.\n",
    "> \n",
    "> ![rag_retrieval_1](./images/rag_retrieval_1.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancing Query Responses by Passing Context and Prompt to LLM\n",
    "\n",
    "### Define a prompt template to provide context to queries\n",
    "\n",
    "Define a prompt template to provide context to our prompts. Thus, when passed to the model, the template will add the necessary context to the prompt so that more accurate results are generated.\n",
    "\n",
    "The answer should contain the requested information about products and their descriptions, formatted according to the specified JSON structure for further use in the SAP HANA JSON Document store.\n",
    "\n",
    "> The created template for the prompt contains two variables - **context** and **question**. These variables will be replaced with the context and question in the upcoming steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"use the following pieces of context to answer the question at the end. If you don't know the answer,\n",
    "    just say you don't know, don't try to make up an answer. Format the results in a list of JSON items with the following keys:\n",
    "\n",
    "        \"PRODUCT_ID\", \n",
    "        \"PRODUCT_NAME\",\n",
    "        \"CATEGORY\",\n",
    "        \"DESCRIPTION\",\n",
    "        \"UNIT_PRICE\",\n",
    "        \"UNIT_MEASURE\",\n",
    "        \"SUPPLIER_ID\",\n",
    "        \"SUPPLIER_NAME\",\n",
    "        \"LEAD_TIME_DAYS\",\n",
    "        \"MIN_ORDER\",\n",
    "        \"CURRENCY\",\n",
    "        \"SUPPLIER_COUNTRY\",\n",
    "        \"SUPPLIER_ADDRESS\",\n",
    "        \"SUPPLIER_CITY\",\n",
    "        \"CITY_LAT\",\n",
    "        \"CITY_LONG\",\n",
    "        \"RATING\"\n",
    "      \n",
    "    \n",
    "    The 'RATING' key value is an integer datatype ranging from 0 stars to 5 stars. Where 0 stars is 'bad' and 5 stars is 'excellent'. Do not include json markdown codeblock syntax in the results for example: ```json ```\n",
    "\n",
    "    {context}\n",
    "\n",
    "    question: {question}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(template = prompt_template, \n",
    "                        input_variables=[\"context\", \"question\"]\n",
    "                       )\n",
    "    \n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Conversational Retrieval Chain with SAP HANA Cloud vector engine\n",
    "\n",
    "\n",
    "This code snippet integrates various components from the `langchain` library to create a retrieval-based question-answering (QA) system. Here's a breakdown of the key parts and their functionality:\n",
    "\n",
    "- **Retriever Initialization:** The `db_ada_table.as_retriever` function is used to initialize a retriever object with specific search arguments (`'k':10`), which likely defines the number of search results to consider.\n",
    "\n",
    "- **Prompt Template :** The `PromptTemplate` was defined in the previous step that instructs how to use the context to answer a question. It emphasizes not to fabricate answers if the information is unavailable. The template also outlines the structure for the expected JSON output with various product and supplier details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "question = \"Find products with a rating of 4 and more.\"\n",
    "retriever = db_ada_table.as_retriever(search_kwargs={'k':10})\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                 retriever=retriever, \n",
    "                 chain_type=\"stuff\",\n",
    "                 chain_type_kwargs= chain_type_kwargs)\n",
    "\n",
    "answer = qa.run(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At this point we have successfully implemented the final step of Retrieval Process and enabled generation of the **contextually relevant answer** based on user's query.\n",
    ">\n",
    "> ![rag_full](./images/rag_full.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have successfully implemented the full Retrieval Augmented Generation (RAG) workflow\n",
    "Please take a screenshot of your BAS workspace at the latest output above and return back to the exercises."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
